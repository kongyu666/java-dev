# \u5C06\u6839\u8BB0\u5F55\u5668\u7EA7\u522B\u8BBE\u7F6E\u4E3ADEBUG\uFF0C\u5E76\u5C06\u5176\u552F\u4E00\u7684appender\u8BBE\u7F6E\u4E3ACONSOLE\u3002
status = error
name = PropertiesConfig

# \u5B9A\u4E49\u6839\u8BB0\u5F55\u5668
property.filename = logs
appenders = console

# \u63A7\u5236\u53F0appender\u914D\u7F6E
appender.console.type = Console
appender.console.name = Console
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = [%-5level] %d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %c{1} - %msg%n

# \u6839\u8BB0\u5F55\u5668\u914D\u7F6E
rootLogger.level = INFO
rootLogger.appenderRefs = console
rootLogger.appenderRef.console.ref = Console

# Spark \u8BB0\u5F55\u5668\u914D\u7F6E
logger.spark.name = org.apache.spark
logger.spark.level = INFO
logger.spark.appenderRefs = console
logger.spark.appenderRef.console.ref = Console
logger.sparkproject.name = org.sparkproject
logger.sparkproject.level = WARN
logger.sparkproject.appenderRefs = console
logger.sparkproject.appenderRef.console.ref = Console
# Hadoop \u8BB0\u5F55\u5668\u914D\u7F6E
logger.hadoop.name = org.apache.hadoop
logger.hadoop.level = INFO
logger.hadoop.appenderRefs = console
logger.hadoop.appenderRef.console.ref = Console